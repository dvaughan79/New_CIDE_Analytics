{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analítica y Ciencia de Datos\n",
    "\n",
    "## CIDE - Otoño 2015\n",
    "\n",
    "### Introducción al Apendizaje Estadístico o Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Referencias para estas notas\n",
    "\n",
    "* Cualquier texto de aprendizaje estadístico o machine learning.\n",
    "\n",
    "* Pero vamos a seguir de cerca los capítulos 1 y 2 de [Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf) y [The Elements of Statistical Learning](http://web.stanford.edu/~hastie/local.ftp/Springer/OLD/ESLII_print4.pdf).\n",
    "\n",
    "* El primero es más introductorio y sirve para entender bien los conceptos.\n",
    "\n",
    "* El tratamiento del segundo es más profundo y riguroso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Qué es Aprendizaje Estadístico?\n",
    "\n",
    "* En términos generales, el aprendizaje estadístico no es más que el uso de modelos estadísticos con el objeto de aprender o descubrir el proceso de generación de unos datos (*data generating process*).\n",
    "\n",
    "* En general hay dos tipos de aprendizaje:\n",
    "    \n",
    "    1. **Aprendizaje supervizado**: \n",
    "    el objetivo es aprender el proceso de generación de una variable o grupo de variables resultado $\\mathbf{y}$ a partir de un grupo de variables predictoras (regresores en el contexto de un modelo de regresión) $\\mathbf{X}$.  \n",
    "    Se llama supervizado porque tenemos a $\\bf y$ guiando o supervizando la calidad de los modelos, y el objetivo es conocer el proceso de generación de datos $f: X \\rightarrow y$:\n",
    "    $$\n",
    "    y = f(X) + \\epsilon\n",
    "    $$\n",
    "    \n",
    "    2. **Aprendizaje no supervizado**: son todos aquellos casos donde pretendemos descubrir ciertas características de los datos $\\bf X$ en ausencia del resultado o outcome.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ¿Para qué utilizar aprendizaje estadístico?\n",
    "\n",
    "Hay dos razones por las que queremos utilizar las técnicas de aprendizaje estadístico:\n",
    "\n",
    "* **Predicción**:  En el caso de aprendizaje estadístico, si tenemos un modelo $\\hat{f}(X)$, podemos estimar $y$:\n",
    "\n",
    "$$\n",
    "E(y) = \\hat{f}(X) + E(\\epsilon) = \\hat{f}(X)\n",
    "$$\n",
    "\n",
    "* **Inferencia**: queremos *entender* cuáles variables $X_1, X_2, \\cdots, X_p$ afectan el resultado $y$, y de qué forma lo hacen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Modelos de regresión y clasificación\n",
    "\n",
    "* Hay dos grandes clases de modelos supervizados que dependen del tipo de variable dependiente $\\bf y$ que tengamos:\n",
    "\n",
    "    * Si la variable es *cuantitativa* o contínua, utilizamos modelos de **regresión**.\n",
    "    \n",
    "    * Si la variable es *categórica* utilizamos modelos de clasificación.\n",
    "    \n",
    "* Por ejemplo, si queremos estimar el ingreso de la gente, en función de su género, edad y educación, utilizamos un modelo de regresión.\n",
    "\n",
    "* Si queremos clasificar a un cliente en dos o más categorías, utilizamos un mosdelo de clasificación.\n",
    "\n",
    "    * Por ejemplo, queremos estimar la probabilidad que un cliente que pide una tarjeta de crédite deje de pagar.\n",
    "    \n",
    "    * Queremos estimar la probabilidad que una persona utilice su carro, el metro, el sistema de buses o la bicicleta.\n",
    "    \n",
    "* En los casos de modelos de clasificación, es usual utilizar etiquetas numéricas.  Por ejemplo:\n",
    "\n",
    "$$ y = \n",
    "\\begin{cases}\n",
    "1 & \\text{si cliente ha dejado de pagar} \\\\\n",
    "0 & \\text{si nunca ha dejado de pagar sus créditos}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "o en el caso de más de una categoría\n",
    "\n",
    "$$ y = \n",
    "\\begin{cases}\n",
    "1 & \\text{si individuo utiliza metro} \\\\\n",
    "2 & \\text{si utiliza carro particular} \\\\\n",
    "3 & \\text{si utiliza bicicleta} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* En estos casos, la etiqueta numérica no tiene un carácter *ordinal*, lo que sí sucede con modelos de regresión donde el carácter ordinal define a la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ¿Cómo aprendemos el proceso de generación de datos? \n",
    "\n",
    "\n",
    "* Si queremos comparar modelos, necesitamos una métrica que nos permita decir si un modelo es mejor que otro.\n",
    "\n",
    "* En modelos de regresión, la métrica estándar es el error cuadrático medio (MSE):\n",
    "$$\n",
    "MSE = \\frac{1}{N}\\sum_i (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "* Así: un modelo $A$ as mejor que un modelo $B$ si $MSE_A < MSE_B$\n",
    "\n",
    "* Alternativamente, si queremos hacer supuestos sobre la distribución del término de error $\\epsilon$, podemos utilizar (el logaritmo de) la función de verosimilitud, $LL(\\theta)$ en el caso de un modelo paramétrico con parámetros a estimar $\\mathbf \\theta$.\n",
    "\n",
    "    * En este caso el mejor modelo es el que tiene un *mayor loglikelihood LL*.\n",
    "    \n",
    "* En el caso paramétrico, lineal en los parámetros $Y = X\\beta + \\epsilon$, ya sabemos que el **estimador de mínimos cuadrados ordinarios** (OLS, por sus siglas en inglés), es la solución al problema de minimizar el MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y en el caso de modelos de clasificación:\n",
    "\n",
    "* En modelos con supuestos sobre la distribución (ejemplo: modelos *Logit* o *Probit*), se puede utilizar la respectiva verosimilitud.\n",
    "\n",
    "* Pero en general podemos usar la **tasa de error**:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_i I(y_i \\neq \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "    * Es decir, para cada observación, sabemos si fue clasificada correcta o incorrectmente.  Si fue incorrecta $y_i \\neq \\hat{y}_i$ la variable indicador toma el valor $1$, si fue correcta toma el valor $0$.\n",
    "    \n",
    "* Los modelos de clasificación suelen tener asociada una probabilidad condicional: $Prob(y_i \\in C_k| x_i)$, es decir, la probabilidad de que una obsevación $i$ sea del tipo $k$, condicional en el valor de sus regresores $x_i = x_{1i},x_{2i}, \\cdots, x_{pi},$.\n",
    "\n",
    "* En estos casos, el clasificador que minimiza la tasa de error se conoce como el **clasificador de Bayes** (\"Bayes classifier\"), y asigna cada observación $i$ a la clase que tiene una mayor probabilidad de ocurrir $k^* = argmax_k Prob(y_i \\in C_k| x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Modelos paramétricos y modelos no paramétricos\n",
    "\n",
    "* **Modelo paramétrico:** si tiene un *número fijo de parámetros*.\n",
    "\n",
    "    * Ejemplo1: $y = \\beta_0 + \\beta_1 x_1 + \\epsilon$\n",
    "    \n",
    "    * Ejemplo2: $Prob(y=1|x,\\beta) = \\Phi(x'\\beta)$, donde $\\Phi()$ es la función de distribución acumulativa de una variable aleatoria normal estándar.\n",
    "    \n",
    "* **Modelo no paramétrico:** si el número de parámetros a estimar crece con el tamaño de los datos y no se hacen supuestos sobre el proceso de formación de datos.\n",
    "\n",
    "    * **K-nearest neighbors**: \n",
    "        \n",
    "        * Queremos clasificar la observación $i$.\n",
    "        * Para hacerlo miramos las categorías de las $K$ observaciones más cercanas de acuerdo con las variables independientes $x$, se obtienen las fracciones empíricas (ej. $1/3$ de los K vecinos son de la categoría $1$ y $2/3$ son de la categoría $0$):\n",
    "        $$\n",
    "        Prob \\left(y_i=c|\\mathbf{x_i},K \\right) = \\frac{1}{K}\\sum_{j \\in N_K(x_i)} I(y_j =c)\n",
    "        $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Datos de entrenamiento y de prueba\n",
    "\n",
    "* En el caso de aprendizaje supervizado, es usual dividir los datos en dos grupos:\n",
    "\n",
    "    * **Datos de entrenamiento (training sample)**: son los datos que utilizamos para estimar o entrenar el modelo.  \n",
    "        * Así, por definición, en el caso OLS, sabemos que los parámetros estimados $\\hat{\\mathbf{\\beta}}$ minimizan el MSE en los datos de entrenamiento.  \n",
    "    \n",
    "    * **Datos de prueba (test sample)**: para calificar la precisión de un modelo utilizamos unos datos distintos a los que fueron necesarios para estimarlo.  Estos son los datos de prueba.\n",
    "    \n",
    "* En econometría hablamos de la predicción dentro (in-sample) y fuera (out-of-sample) de la muestra.  \n",
    "    \n",
    "* En aprendizaje de datos esta es una parte fundamental del método de aprendizaje.\n",
    "\n",
    "* Dividir los datos en conjuntos de entrenamiento y prueba nos protege de problemas como **overfitting**: el MSE es no creciente en el número de regresores (por eso usamos el $\\bar{R}^2$ en econometría)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# El tradeoff entre varianza y sesgo\n",
    "\n",
    "* El MSE se puede descomponer en la varianza y el sesgo.\n",
    "\n",
    "* Denotemos los datos por $\\mathcal{D} = \\{x_1, x_2, \\cdots, x_N\\}$\n",
    "\n",
    "* Sean \n",
    "    * $\\hat{\\theta} = \\hat{\\theta}(\\mathcal{D})$ nuestra estimación, \n",
    "    \n",
    "    * $\\bar{\\theta} = E(\\hat{\\theta})$ el valor esperado de la estimación cuando variamos los datos.\n",
    "    \n",
    "    * $\\theta^*$ el parametro verdadero.\n",
    "    \n",
    "* El MSE se puede escribir como:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "E\\left[(\\hat{\\theta} - \\theta^*)^2 \\right] &=& E\\left[\\left[(\\hat{\\theta} - \\bar{\\theta}) + (\\bar{\\theta} - \\theta^*) \\right]^2\\right]\\\\\n",
    "&=& E(\\hat{\\theta} - \\bar{\\theta})^2 + 2(\\bar{\\theta} - \\theta^*)E(\\hat{\\theta} - \\bar{\\theta}) + E(\\bar{\\theta} - \\theta^*)^2\\\\\n",
    "&=& Var(\\hat{\\theta}) + Bias^2\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "* La *varianza* se refiere a cuánto cambia la estimación si utilizamos otros datos de entrenamiento.\n",
    "\n",
    "* El *sesgo* se refiere al error sistemático que se obtiene al aproximar el proceso de generación de datos verdadero por medio de un modelo simple.\n",
    "\n",
    "* Por ejemplo, de nuestras clases de econometría sabemos que las *omitir variables* sesga la estimación.\n",
    "\n",
    "* El tradeoff sugiere que a veces queremos **sacrificar un poco de *sesgo* si reducimos la *varianza* de la estimación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
