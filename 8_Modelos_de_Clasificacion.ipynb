{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analítica y Ciencia de Datos\n",
    "\n",
    "## CIDE - Otoño 2015\n",
    "\n",
    "### Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Referencias\n",
    "\n",
    "Capítulo 4 de [ESL](http://web.stanford.edu/~hastie/ElemStatLearn/).\n",
    "\n",
    "Capítulo 4 de [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "Capítulos de Modelos de Elección Discreta de un texto econométrico (Greene, Wooldridge o Cameron y Trivedi). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción a los Modelos de Clasificación\n",
    "\n",
    "\n",
    "* En las notas [introductorias](6_Intro_MachineLearning.ipynb) mencionamos algunos de los conceptos que siguen a continuación.\n",
    "\n",
    "\n",
    "* A diferencia de los modelos de regresión, los modelos de clasificación tienen como objetivo estimar la probabilidad de pertenecer a una categoría $k = 1, \\cdots, K$.\n",
    "\n",
    "\n",
    "* La variable dependiente $y_i$ es una variable *categórica* que indica a qué categoría pertenece el individuo $i$.\n",
    "\n",
    "\n",
    "* Así, $y_i \\in \\{1,0\\}$ indica la pertenencia a una de dos categorías, y las etiquetas $1,0$ carecen de contenido numérico u ordinal, así que los podríamos haber permutado, o nombrado de la manera que queramos.\n",
    "\n",
    "\n",
    "* Ejemplo del mundo de los negocios abundan:\n",
    "\n",
    "    * ¿Es el cliente alguien que potencialmente no paga su tarjeta de crédito?\n",
    "    \n",
    "    * ¿Es un cliente *fiel*, o nos abandonará en el siguiente período?\n",
    "    \n",
    "    * ¿Si le ofrecemos el producto, el cliente lo aceptará?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errores de Clasificación\n",
    "\n",
    "* A diferencia de un modelo de regresión, la estructura no ordinal de la variable dependiente enriquece el análisis de errores que podemos hacer para evaluar un modelo.\n",
    "\n",
    "\n",
    "* En regresión teníamos que una métrica de ajuste o error de un modelo era la *suma de residuos al cuadrado*.\n",
    "\n",
    "\n",
    "* En el caso de modelos de clasificación esta estructura es más rica.\n",
    "\n",
    "\n",
    "* Podemos empezar con el **error de clasificación**:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{i=1}^N I[\\hat{y}_i \\neq y_i]\n",
    "$$\n",
    "\n",
    "donde $I[x]$ es una variable indicadora que toma el valor $1$ cuando $x$ es verdadera y $0$ en caso contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Pero cómo clasificamos?\n",
    "\n",
    "* Todavía no está claro, pero eventualmente formularemos modelos de la probabilidad de pertenecer a una categoría. \n",
    "\n",
    "\n",
    "* El resultado del modelo es una probabilidad estimada $\\hat{p}_{ik}$ de que el individuo $i$ pertenezca a la categoría $k \\in 1, \\cdots, K$.\n",
    "\n",
    "\n",
    "* La probabilidad nos da una medida contínua de pertenecer a una categoría, pero nuestro objetivo es predicir la categoría.\n",
    "\n",
    "\n",
    "* Así, por ejemplo, podemos decir que el individuo $i$ pertenece a la categoría que maximiza la probabilidad.\n",
    "\n",
    "    * En el caso de dos categorías: la predicción es \n",
    "    $$\n",
    "    i \\hat{\\in} k \\iff \\hat{p}_{ik}>0.5\n",
    "    $$\n",
    "    \n",
    "   \n",
    "* Pero **noten** que el valor límite o *threshold* $0.5$ es arbitrario, y más adelante veremos que podemos utilizar cualquiera en el intervalo $[min(\\hat{p}_{i,k}), max(\\hat{p}_{i,k})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Matrices de Confusión\n",
    "\n",
    "\n",
    "* Veamos el caso más simple de dos categorías $y_i \\in \\{0,1\\}$.\n",
    "\n",
    "\n",
    "* Aunque el error de clasificación anterior permite tener una primera métrica, para nosotros puede ser más relevante clasificar mal a una categoría que a otra.\n",
    "\n",
    "* Para esto se crea una matriz de confusión, donde las filas denotan la clasificación real u observada y las columnas la clasificación que se obtiene del modelo.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "& \\bf \\hat{0} & \\bf \\hat{1} \\\\\n",
    "\\hline\n",
    "\\bf 0 & \\text{Verdaderos Positivos} & \\text{Falsos Negativos} \\\\\n",
    "\\hline\n",
    "\\bf 1 & \\text{Falsos Positivos} & \\text{Verdaderos Negativos} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "* Acá estamos siguiendo la tradición en esta literatura de denotar a la categoría $1$ como un negativo, y la categoría $0$ como positivo.\n",
    "\n",
    "\n",
    "* Lo importante es entender que con $K$ categorías tenemos la posibilidad de encontrar $K$ errores de clasificación distintos.\n",
    "\n",
    "* Hay dos métricas importantes que se obtienen de una matriz de confusión:\n",
    "\n",
    "    1. **Sensibilidad**: o tasa de verdaderos positivos\n",
    "    $$\n",
    "    \\text{sensibilidad} = \\frac{VP}{VP + FN}\n",
    "    $$\n",
    "    \n",
    "    2. **Especificidad**: o tasa de verdaderos negativos\n",
    "    $$\n",
    "    \\text{especificidad} = \\frac{VN}{VN + FP}\n",
    "    $$\n",
    "    \n",
    "* En el contexto de modelos de clasificación:\n",
    "\n",
    "    * **Error Tipo 1:** o falso positivo: $1-\\text{especificidad}$\n",
    "    * **Error Tipo 2:** o falso negativo: $1-\\text{sensibilidad}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Curvas ROC\n",
    "\n",
    " ![caption](figures/roc_curve.png)\n",
    " \n",
    "Figura 4.8 de ISL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Curvas ROC (cont.)\n",
    "\n",
    "\n",
    "* Las tasas de verdaderos positivos y falsos positivos son una buena medida del comportamiento de un modelo.\n",
    "\n",
    "\n",
    "* Sin embargo, dependen crucialmente del *threshold que utilicemos*.\n",
    "\n",
    "\n",
    "* La curva ROC permite mirar cómo cambian las tasas de verdadero y falsos positivos a medida que variamos los *thresholds* de clasificación.\n",
    "\n",
    "$$\n",
    "i \\hat{\\in} 0 \\iff \\hat{p}_{i0} > \\tau\n",
    "$$\n",
    "\n",
    "\n",
    "* Así, si $\\tau = 1$ la matriz de confusión es\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "& \\bf \\hat{0} & \\bf \\hat{1} \\\\\n",
    "\\hline\n",
    "\\bf 0 & 0 & n_0 \\\\\n",
    "\\hline\n",
    "\\bf 1 & 0 & n_1 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "donde $n_i = \\#\\{\\text{$i$ en la muestra de entrenamiento}\\}$ y\n",
    "\n",
    "$$\n",
    "\\text{sensibilidad} = 0$, $1-\\text{especificidad} = 0\n",
    "$$\n",
    "\n",
    "obteniendo el punto en la esquina inferior izquierda de la curva ROC.\n",
    "\n",
    "* De la misma forma $\\tau=0$ implica que todas las observaciones se asignan a la categoría $0$ y obtenemos el punto superior derecho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Curvas ROC (cont.)\n",
    "\n",
    "* ¿Qué pasa con la diagonal?\n",
    "\n",
    "* Los puntos de la diagonal tienen la característica que los errores de clasificación en una u otra categoría son exactamente iguales.\n",
    "\n",
    "* Corresponden a una asignación aleatoria (un \"volado\")\n",
    "\n",
    "    * Sirve como referencia o benchmark para medir a nuestros modelos.\n",
    "    \n",
    "\n",
    "* Intuitivamente quisieramos modelos que estén muy lejos de la diagonal.\n",
    "\n",
    "\n",
    "* Matemáticamente, quisieramos que el **área debajo de la curva** (AUC) sea lo mayor posible.\n",
    "\n",
    "\n",
    "* Noten el parecido con el coeficiente de Gini.  Todas las dificultades que se conocen para comparar distribuciones de ingreso mediante el coeficiente de Gini son válidas acá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costos directos, indirectos y de oportunidad\n",
    "\n",
    "* Una alternativa con modelos de clasificación es tener una medida del costo esperado de un modelo, es decir, tener en cuenta las asimetrías entre un clasificación correcta de cada alternativa.\n",
    "\n",
    "\n",
    "* Tomemos el caso de un modelo de *credit scoring*\n",
    "\n",
    "$$\n",
    "y_i = \n",
    "\\begin{cases}\n",
    "1 & \\text{si cliente $i$ ha dejado de pagar sus créditos}\\\\\n",
    "0 & \\text{si cliente $i$ ha pagado sus créditos}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "* El score crediticio es una función de la probabilidad de que el cliente pague.\n",
    "\n",
    "\n",
    "* Así, un *menor* score sugiere que hay una mayor probabilidad de incumplimiento o de impago.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejemplo Score Crediticio\n",
    "\n",
    "\n",
    "* Supongamos que la matriz de confusión para un modelo y *threshold* dados es\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "& \\bf \\hat{0} & \\bf \\hat{1} \\\\\n",
    "\\hline\n",
    "\\bf 0 & n_{00} & n_{01} \\\\\n",
    "\\hline\n",
    "\\bf 1 & n_{10} & n_{11} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Miremos caso por caso:\n",
    "\n",
    "\n",
    "* **Caso $0\\hat{0}$**: cliente bueno y el modelo lo asigna correctamente.  Le damos una TdC, y nos deja una rentabilidad promedio de $r_{00} >0$.\n",
    "\n",
    "\n",
    "* **Caso $0\\hat{1}$**: cliente bueno pero el modelo lo clasifica como uno malo.  *No* le damos crédito, así que obtenemos una rentabilidad $r_{01} = 0$. $\\Rightarrow$ **Costo de oportunidad de mala clasificación!**\n",
    "\n",
    "\n",
    "* **Caso $1\\hat{0}$**: cliente malo, pero el modelo lo clasifica como si fuera bueno.  Le damos una TdC y no nos paga $r_{10}<0$.  $\\Rightarrow$ **costo directo de mala clasificación**\n",
    "\n",
    "\n",
    "* **Caso $1\\hat{1}$**: clientes malo y está bien clasificado.  No le damos una TdC, así que $r_{11} = 0$.\n",
    "\n",
    "\n",
    "##### ¿Cuál es la rentabilidad esperada que obtenemos del modelo?\n",
    "\n",
    "$$\n",
    "E(r|\\mathcal{M}) = \\sum_{ij} p_{ij}r_{ij}  = p_{00}r_{00} + p_{10}r_{10}\n",
    "$$\n",
    "\n",
    "donde $p_{ij} = n_{ij}/ \\sum_{kl} n_{kl}$\n",
    "\n",
    "##### ¿Cuál es la rentabilidad esperada que obtenemos del modelo, si incluimos el costo de oportunidad?\n",
    "$$\n",
    "E(r_{co}|\\mathcal{M}) = r_{00}(p_{00} - p_{01}) + p_{10} r_{10}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos lineales de probabilidad\n",
    "\n",
    "\n",
    "* Cuando hay sólo dos categorías, $y_i \\in {0,1}$, es posible estimar por OLS el modelo.\n",
    "\n",
    "$$\n",
    "y_i = x_i' \\beta + \\epsilon_i\n",
    "$$\n",
    "\n",
    "\n",
    "* ¿Por qué se llama un **modelo lineal de probabilidad**?\n",
    "\n",
    "\n",
    "* En general, queremos modelar \n",
    "$$\n",
    "Prob(y=1|X) = F(X,\\beta)\n",
    "$$\n",
    "\n",
    "Si $F(X,\\beta) = x\\beta$, entonces $E(y|x) = x\\beta$, y tenemos el modelo lineal.\n",
    "\n",
    "\n",
    "\n",
    "* Los modelos lineales de probabilidad tienen dos problemas:\n",
    "\n",
    "    1. Nada garantiza que $\\hat{y}_i \\in [0,1]$, afectando la interpretación del modelo.\n",
    "    \n",
    "    2. Heteroscedasticidad.\n",
    "    $$\n",
    "    Var(\\epsilon_i) = x_i'\\beta(1-x_i'\\beta)\n",
    "    $$\n",
    "\n",
    "\n",
    "* ¿Cómo se soluciona este problema?  En la **tarea** lo tendrán que hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos Probit\n",
    "\n",
    "\n",
    "* Una alternativa natural es asumir que $F(x_i,\\beta) = \\Phi(x_i'\\beta)$, donde $\\Phi$ es la función de distribución de una variable aleatoria normal estándar.\n",
    "\n",
    "\n",
    "* Este tipo de modelos es ampliamente utilizado en econometría, así que no los cubriremos en el curso.\n",
    "\n",
    "\n",
    "* Si miraremos a profundidad los modelos logísticos o Logit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos Logit\n",
    "\n",
    "\n",
    "* Otra alternativa es usar \n",
    "$$\n",
    "F(x_i,\\beta) = \\Lambda(x_i'\\beta) = \\frac{e^{x_i'\\beta}}{1+e^{x_i'\\beta}}\n",
    "$$\n",
    "\n",
    "\n",
    "donde $\\Lambda(x_i'\\beta)$ denota a la función acumulativa logística.\n",
    "\n",
    "\n",
    "* ¿Cuál es el valor esperado de $y$?\n",
    "\n",
    "$$\n",
    "E(y|x) = 1 \\times F(x,\\beta) + 0 \\times (1-F(x,\\beta)) = F(x,\\beta)\n",
    "$$\n",
    "\n",
    "\n",
    "* Para encontrar los efectos marginales: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(y|x)}{\\partial x} = \\left[\\frac{d F(x,\\beta)}{d x'\\beta}\\right] \\beta = f(x,\\beta) \\beta\n",
    "$$\n",
    "\n",
    "donde $f()$ es la función de densidad.\n",
    "\n",
    "### Nota:\n",
    "##### A diferencia del modelo lineal de probabilidad donde los efectos marginales son constantes, los efectos marginales en los modelos Logit y Probit son funciones de $x$ y $\\beta$.   Generalmente se reportan *evalúandolos en las medias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Efectos marginales del Logit\n",
    "\n",
    "\n",
    "* En el caso del Logit es inmediato mostrar que:\n",
    "\n",
    "$$\n",
    "f(x,\\beta) = \\frac{e^{x'\\beta}}{(1+e^{x'\\beta})^2} = \\Lambda(x'\\beta)(1-\\Lambda(x'\\beta))\n",
    "$$\n",
    "\n",
    "* Así que para el caso de regresores contínuos podemos utilizar la fórmula de la diapósitiva anterior:\n",
    "\n",
    "$$\n",
    "\\text{Efectos Marginales} = \\frac{\\partial E(y|x)}{\\partial x_k} =  \\Lambda(\\overline{x}'\\beta)(1-\\Lambda(\\overline{x}'\\beta)) \\beta_k\n",
    "$$\n",
    "\n",
    "donde $\\overline{x} := [\\overline{x}_1, \\cdots, \\overline{x}_p]$.\n",
    "\n",
    "\n",
    "* En el caso de regresores categóricos (variables dummy), la derivada se reemplaza por el efecto marginal:\n",
    "\n",
    "$$\n",
    "\\text{Efectos Marginales regresor k} = Prob \\left(y=1 \\Bigg\\vert \\overline{x}_{(d)}, x_k=1 \\right) - Prob \\left(y=1 \\Bigg\\vert  \\overline{x}_{(d)}, x_k=0 \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Estimación de los modelos Logit\n",
    "\n",
    "* Para estimar el modelo es necesario maximizar la logverosimilitud\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\mathcal{l}(\\beta) &=& \\sum_{i=1}^N \\log p_{g_i}(x_i;\\beta)\\\\\n",
    "&=& \\sum_{i=1}^N y_i \\ln \\Lambda(x_i,\\beta) + (1-y_i) \\ln (1-\\Lambda(x_i,\\beta))\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "* Las condiciones de primer orden son:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{l}}{\\partial \\beta} = \\sum_{i} (y_i - \\Lambda_i)\\mathbf{x}_i = \\mathbf{0} = X'(y-\\hat{p})\n",
    "$$\n",
    "\n",
    "* El Hessiano es\n",
    "\n",
    "$$\n",
    "H = \\frac{\\partial^2 \\mathcal{l}}{\\partial \\beta \\partial \\beta'} = -\\sum_{i} \\Lambda_i (1-\\Lambda_i)\\mathbf{x}_i\\mathbf{x}_i' = X'WX \n",
    "$$\n",
    "\n",
    "con $W = diag(\\Lambda_i (1-\\Lambda_i))$\n",
    "\n",
    "* Se puede demostrar que la función de verosimilitud es globalmente cóncava, así que existen métodos numéricos iterativos eficientes para resolverlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# El Método de Newton y Mínimos Cuadrados Ponderados Iterativamente (IRLS)\n",
    "\n",
    "* Supongamos que tenemos una estimación para la iteración $k$: $\\beta_{(k)}$\n",
    "\n",
    "\n",
    "* Vamos a hacer una aproximación de primer orden alrededor de esta estimación utilizando la condición de primer orden\n",
    "\n",
    "$$\n",
    "f(\\beta_{(k+1)}) \\approx f(\\beta_{(k)}) + \\nabla f(\\beta_{(k)})(\\beta_{(k+1)}-\\beta_{(k)})\n",
    "$$\n",
    "\n",
    "donde el gradiente $\\nabla$ de la condición de primer orden es el Hessiano\n",
    "\n",
    "\n",
    "* asumiendo que convergimos y el lado izquierdo es cero, despejando obtenemos la iteración de Newton\n",
    "\n",
    "$$\n",
    "\\beta_{(k+1)} = \\beta_{(k)} -  \\nabla f(\\beta_{(k)})^{-1}f(\\beta_{(k)})\n",
    "$$\n",
    "\n",
    "* Reemplazando, obtenemos\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\beta_{(k+1)} &=& \\beta_{(k)} + (X'WX)^{-1}X'(y-\\hat{p})\\\\\n",
    "&=& (X'WX)^{-1}X'[WX\\beta_{(k)} + (y-\\hat{p})] \\\\\n",
    "&=& (X'WX)^{-1}X'W[X\\beta_{(k)} + W^{-1}(y-\\hat{p})] \\\\\n",
    "&=& (X'WX)^{-1}X'W z\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "con $z = X\\beta_{(k)} + W^{-1}(y-\\hat{p})$\n",
    "\n",
    "\n",
    "* Así que en cada iteración obtenemos una nueva estimación que es el resultado de estimar por mínimos cuadrados ponderados una regresión de $z$ en $X$ utilizando $W$ como matriz de ponderadores.\n",
    "\n",
    "\n",
    "* Este método converge muy rápidamente y tendrán que programarlo en la **tarea**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
